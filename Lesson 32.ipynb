{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "from math import *\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 32: Likelihood Ratio Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time, we introduced Likelihood Ratio tests. Recall that the point of a likelihood ratio test is to compare the likelihood function under a hypothesized value of the parameter with the liklihood function at its maximum. Instead of looking at the ratio $\\Lambda$ itself, we often consider $-2\\log \\Lambda$ instead, since it has a handy distribution. \n",
    "\n",
    "### Example 1: Exponential Distribution\n",
    "\n",
    "Suppose $X_1,X_2,...,X_n$ is an iid sequence of random variables from the exponential distribution with unknown parameter $\\lambda$. Recall that the maximum likelihood estimate of $\\lambda$ is $1\\over\\bar{X}$. We collect a random sample of size 20 and want to test the hypothesis $H_0: \\lambda = 3$ vs $H_1: \\lambda \\neq 3$. Using the data in the python box below, conduct a likelihood ratio test on this hypothesis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data=np.array([0.18,0.277,0.105,0.126,0.225,0.026,0.123,0.423,0.006,0.281,0.050,0.692,0.105,0.275,0.346,0.079,0.045,0.222,0.063,0.281])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Lambda=\\frac{L(\\lambda\\mid\\textbf{x})}{L(\\hat{\\lambda}_{ML}\\mid\\textbf{x})}\n",
    "$$\n",
    "$$\n",
    "-2\\log \\Lambda = 2\\left[n \\log \\hat{\\lambda}_{ML} - \\hat{\\lambda}_{ML} \\sum x_i-n \\log \\lambda_0 - \\lambda_0 \\sum x_i\\right] \n",
    "$$\n",
    "$$\n",
    "-2\\log \\Lambda = 2\\left[n \\log \\hat{\\lambda}_{ML} - \\hat{\\lambda}_{ML} n \\bar{X}- n \\log \\lambda_0 + n \\right] \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7192223601884535"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam_not = 1/np.mean(my_data)\n",
    "test_stat = -2*(20*np.log(3)-20*3*np.mean(my_data)-20*np.log(lam_not)+20)\n",
    "test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029827229194775318"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-stats.chi2.cdf(test_stat,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power\n",
    "\n",
    "Suppose that the true value of $\\lambda$ is 5. Let's determine the power of this test. Let $n=20$. Then determine the power if $n=50$. Remember, power is the probability of correctly rejecting the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, find what value of $-2 \\log \\Lambda$ would lead you to reject $H_0$. This is sometimes called the critical value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.841458820694124"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit = stats.chi2.ppf(.95,1)\n",
    "crit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, obtain the power. Obtain a sample of size 20 from the true population and obtain the value of $-2\\log \\Lambda$ for this sample. Repeat many times and determine how often you reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_stat(data, null, n):\n",
    "    lam_not = 1/np.mean(data)\n",
    "    return -2*(n*np.log(null)-n*null*np.mean(data)-n*np.log(lam_not)+n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7192223601884535"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_stat(my_data, null=3, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5978"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(500)\n",
    "sims = 10000\n",
    "test = make_array()\n",
    "for i in np.arange(sims):\n",
    "    x = stats.expon.rvs(scale=1/5, size=20)\n",
    "    test = np.append(test, log_stat(x, 3, 20))\n",
    "\n",
    "sample_20 = np.mean(test>=crit)\n",
    "sample_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for a sample size of 50. What do you expect to happen to power? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = make_array()\n",
    "for i in np.arange(sims):\n",
    "    y = stats.expon.rvs(scale=1/5, size=50)\n",
    "    test2 = np.append(test2, log_stat(y, 3, 50))\n",
    "\n",
    "sample_50 = np.mean(test2>=crit)\n",
    "sample_50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Different Test\n",
    "\n",
    "We've explored hypothesis tests in this class before. Taking advantage of our computing power, we don't have to rely on test statistics with asymptotic distributions. Let's conduct a more direct hypothesis test using simulation. Recall:\n",
    "\n",
    "$$\n",
    "H_0: \\lambda = 3\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_1: \\lambda \\neq 3\n",
    "$$\n",
    "\n",
    "Pick a different test statistic. Obtain an empirical distribution of that test statistic under $H_0$. Next, find the $p$-value by determining how often this test statistic is at or further away from the test statistic derived from the sample. Remember that this is a two-sided test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3 = make_array()\n",
    "for i in np.arange(sims):\n",
    "    z = np.mean(stats.expon.rvs(scale=1/3, size=20))\n",
    "    test3 = np.append(test3, z)\n",
    "\n",
    "sample3 = 2*np.mean(test3<=np.mean(my_data))\n",
    "sample3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the $p$-value compare to the LRT $p$-value? I wonder how the power of this test compares to our LRT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power\n",
    "\n",
    "Let's figure out the power of this test. First, determine for what values of the test statistic would lead us to reject $H_0$. These values can be referred to as your rejection region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20359198580601992 0.49241447042545083\n"
     ]
    }
   ],
   "source": [
    "low = percentile(2.5,test3)\n",
    "high = percentile(97.5,test3)\n",
    "print(low, high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, determine the power of this test. Like in the LRT case, obtain a sample of size 20 and obtain the test statistic. Repeat many times and see how often your test statistic is in your rejection region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5584"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test4 = make_array()\n",
    "for i in np.arange(sims):\n",
    "    a = np.mean(stats.expon.rvs(scale=1/5, size=20))\n",
    "    test4 = np.append(test4, a)\n",
    "\n",
    "sample4 = np.mean(test4<=low) + np.mean(test4>=high)\n",
    "sample4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for a sample size of 50. Note that you will have to obtain new critical values in order to do this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.247186851622122 0.4367263789776643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9437"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3 = make_array()\n",
    "for i in np.arange(sims):\n",
    "    z = np.mean(stats.expon.rvs(scale=1/3, size=50))\n",
    "    test3 = np.append(test3, z)\n",
    "\n",
    "sample3 = 2*np.mean(test3<=np.mean(my_data))\n",
    "sample3\n",
    "\n",
    "low = percentile(2.5,test3)\n",
    "high = percentile(97.5,test3)\n",
    "print(low, high)\n",
    "\n",
    "test4 = make_array()\n",
    "for i in np.arange(sims):\n",
    "    a = np.mean(stats.expon.rvs(scale=1/5, size=50))\n",
    "    test4 = np.append(test4, a)\n",
    "\n",
    "sample4 = np.mean(test4<=low) + np.mean(test4>=high)\n",
    "sample4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
